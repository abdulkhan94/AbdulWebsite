{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers = ['localhost:9092'], api_version=(0,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send('quickstart-events',b'Hello, Kafka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 5\n",
    "tester = {'name':'Tarang', 'occupation':'Baller', 'income':'1000000000'}\n",
    "for _ in range(3):\n",
    "    tester['day'] = j\n",
    "    j += 1\n",
    "    message = bytes(json.dumps(tester), 'utf-8')\n",
    "    producer.send('quickstart-events', message)\n",
    "    sleep(2)\n",
    "    print(f\"Message sent... {json.loads(str(message, 'utf-8'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tester.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tester.get('khan') == None:\n",
    "    print('Dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers = ['localhost:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = {}\n",
    "with open('tester.csv','r') as original:\n",
    "    for line in original:\n",
    "        send_list = line.strip().split(',')\n",
    "        if send_list[0] != 'name':\n",
    "            sender['name'] = send_list[0]\n",
    "            sender['age'] = int(send_list[1])\n",
    "            sender['occupation'] = send_list[2]\n",
    "            message = bytes(json.dumps(sender),\"utf-8\")\n",
    "            producer.send('test-events', message)\n",
    "            print(f'Sent message ... {str(message,\"utf-8\")}')\n",
    "            sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = {}\n",
    "with open('tester.csv', 'r') as original:\n",
    "    for line in original:\n",
    "        print(line)\n",
    "        listt = line.strip().split(',')\n",
    "        if listt[0] != 'name' and listt[0] != '' and listt[1] != '' and listt[2] != '':\n",
    "            sender['name'] = listt[0]\n",
    "            sender['age'] = int(listt[1])\n",
    "            sender['occupation'] = listt[2]\n",
    "            print(sender)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "from time import sleep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "with open('test.txt', 'r') as original:\n",
    "    alpha = original.read()\n",
    "    word_list = re.findall(r\"\\b\\w+\",alpha)\n",
    "    for word in word_list:\n",
    "        print(word)\n",
    "        message = bytes(word,\"utf-8\")\n",
    "        producer.send('test-events', message)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from datetime import time, timedelta, date\n",
    "import json\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "with open('tester.csv','r') as original:\n",
    "    for line in original:\n",
    "        data_line = line.strip().split(',')\n",
    "        if data_line[0] != 'name' and data_line[0] != '' and data_line[1] != '' and data_line[2] != '':\n",
    "            data_dict['name'] = data_line[0]\n",
    "            data_dict['age'] = int(data_line[1])\n",
    "            data_dict['occupation'] = data_line[2]\n",
    "            message = bytes(json.dumps(data_dict), \"utf-8\")\n",
    "            producer.send('test-events',message)\n",
    "            print(f'Message sent ... {json.loads(str(message,\"utf-8\"))}')\n",
    "            sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from datetime import datetime, time\n",
    "import json\n",
    "\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "    data = (pipeline \n",
    "                | \"read from kafka\" >> beam.io.readfromkafka(bootstrap_servers=9092)\n",
    "                | \"readwindow\" >> beam.WindowInto(window.Sessions(60))\n",
    "                | \"transform to dict\" >> beam.Map(lambda x: json.loads(str(x,\"utf-8\")))\n",
    "           ) #Other options are beam.WindowInto(window.FixedWindows/SlidingInto)\n",
    "    \n",
    "    aggregations = (data \n",
    "                    | \"Extract age\" >> beam.Map(lambda z: ('age', z['age']))\n",
    "                    | \"combine per key\" >> beam.CombinePerKey(sum)\n",
    "                    | \"create age string\" >> beam.Map(lambda h: f'{h(1)}')\n",
    "                    | \"writetocassandra\" >> beam.CassandraIO.Write(keyspace=\"\", table=)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={}\n",
    "with open('tester.csv','r') as original:\n",
    "    for line in original:\n",
    "        data_list = line.strip().split(',')\n",
    "        if data_list[0] != 'name' and data_list[0] != '' and data_list[1] != '' and data_list[2] != '':\n",
    "            data_dict['name'] = data_list[0]\n",
    "            data_dict['age'] = int(data_list[1])\n",
    "            data_dict['occupation'] = data_list[2]\n",
    "            message = bytes(json.dumps(data_dict), \"utf-8\")\n",
    "            producer.send('test-events', message)\n",
    "            print(f\"Sent message ... {json.loads(str(message,'utf-8'))}\")\n",
    "            sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as newfile:\n",
    "    data_str = newfile.read()\n",
    "    data_list = re.findall(r\"\\b\\w+\",data_str)\n",
    "    for x in data_list:\n",
    "        message = bytes(x,\"utf-8\")\n",
    "        producer.send(\"test-events\", message)\n",
    "        print(f\"Message sent ... {str(message, 'utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.pipeline as pipeline:\n",
    "    data = (pipeline \n",
    "                | \"Read from Kafka\" >> beam.io.readfromkafka(bootstrap_servers=['localhost:9092'])\n",
    "                | \"Define window\" >> beam.io.WindowInto(window.Sessions(60))\n",
    "                | \"Convert to dict\" >> beam.Map(lambda x: json.loads(str(x),\"utf-8\"))\n",
    "           )\n",
    "    agggregate_data = (data\n",
    "                       | \"Convert to key-value pair\" >> beam.Map(lambda z: (age, z['age']))\n",
    "                       | \"Combine per key\" >> beam.CombinePerKey(Sum)\n",
    "                       | \"Send aggregated age\" >> beam.Map(lambda j: f'{j[1]}')\n",
    "                       | \"Write to Cassandra\" >> beam.CassadraIO.Write(keyspace='')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from kafka import KafkaProducer\n",
    "from datetime import time, timedelta, datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent ... {'name': 'Abdul', 'age': 20, 'occupation': 'Software Engineer'}\n",
      "Message sent ... {'name': 'Joe', 'age': 20, 'occupation': 'System Engineer'}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "with open('tester.csv','r') as original:\n",
    "    for line in original:\n",
    "        data_list = line.strip().split(',')\n",
    "        if data_list[0] != 'name' and data_list[0] != '' and data_list[1] != '' and data_list[2] != '':\n",
    "            data_dict['name'] = data_list[0].strip()\n",
    "            data_dict['age'] = int(data_list[1])\n",
    "            data_dict['occupation'] = data_list[2].strip()\n",
    "            message = bytes(json.dumps(data_dict),\"utf-8\")\n",
    "            #producer.send(\"test-events\", message)\n",
    "            print(f'Message sent ... {json.loads(str(message, \"utf-8\"))}')\n",
    "            sleep(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers = ['localhost:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent ... abdul\n",
      "Message sent ... is\n",
      "Message sent ... is\n",
      "Message sent ... is\n",
      "Message sent ... fun\n",
      "Message sent ... computer\n",
      "Message sent ... abdul\n",
      "Message sent ... is\n",
      "Message sent ... fun\n"
     ]
    }
   ],
   "source": [
    "with open('test.txt', 'r') as original:\n",
    "    data = original.read()\n",
    "    data_list = re.findall(r\"\\b\\w+\",data)\n",
    "    for i in data_list:\n",
    "        message = bytes(i, \"utf-8\")\n",
    "        print(f'Message sent ... {str(message, \"utf-8\")}')\n",
    "        producer.send(\"test-events\", message)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.pipeline(options=OPTIONS) as pipeline:\n",
    "    data = (pipeline \n",
    "            | \"Read from Kafka\" >> beam.io.ReadFromKafka(bootstrap_servers=['localhost:9092'])\n",
    "            | \"Define window\" >> beam.WindowInto(window.Sessions(60))\n",
    "            | \"Convert to dict\" >> beam.Map(lambda x: str(x, \"utf-8\"))\n",
    "           )\n",
    "    next = (data\n",
    "            | \"Create (word,1)\" >> beam.Map(lambda j: (j,1))\n",
    "            | \"Combine per key\" >> beam.CombinePerKey(Sum)\n",
    "            | \"Write to Cassandra\" >> beam.CassandraIO.Write(keyspace='')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
